package commands

import (
	"context"
	"fmt"
	"time"

	"github.com/hashicorp/go-hclog"

	"github.com/hashicorp-forge/hermes/pkg/ai"
	"github.com/hashicorp-forge/hermes/pkg/indexer"
	"github.com/hashicorp-forge/hermes/pkg/search"
)

// IndexVectorCommand indexes document embeddings into a vector search index.
// This enables semantic search and similarity-based document discovery.
type IndexVectorCommand struct {
	VectorDB search.VectorIndex
	Logger   hclog.Logger
}

// Name returns the command name.
func (c *IndexVectorCommand) Name() string {
	return "index-vector"
}

// Execute indexes vector embeddings for a document.
func (c *IndexVectorCommand) Execute(ctx context.Context, doc *indexer.DocumentContext) error {
	if c.Logger == nil {
		c.Logger = hclog.NewNullLogger()
	}

	if c.VectorDB == nil {
		return fmt.Errorf("vector search index is required")
	}

	// Get embeddings from context (generated by previous command)
	embeddingsVal, ok := doc.GetCustom("ai_embeddings")
	if !ok {
		c.Logger.Debug("no embeddings found, skipping vector indexing",
			"document_id", doc.Document.ID,
		)
		return nil
	}

	embeddings, ok := embeddingsVal.(*ai.DocumentEmbeddings)
	if !ok {
		return fmt.Errorf("invalid embeddings type in context")
	}

	// Skip if no content embedding
	if len(embeddings.ContentEmbedding) == 0 {
		c.Logger.Debug("no content embedding, skipping vector indexing",
			"document_id", doc.Document.ID,
		)
		return nil
	}

	c.Logger.Info("indexing vector embeddings",
		"document_id", doc.Document.ID,
		"title", doc.Document.Name,
		"dimensions", embeddings.Dimensions,
		"chunks", len(embeddings.Chunks),
	)

	// Build vector document for indexing
	vectorDoc := &search.VectorDocument{
		ObjectID:         doc.Document.ID,
		DocID:            doc.Document.ID,
		Title:            doc.Document.Name,
		ModifiedAt:       doc.Document.ModifiedTime,
		ContentEmbedding: embeddings.ContentEmbedding,
		Model:            embeddings.Model,
		Dimensions:       embeddings.Dimensions,
		EmbeddedAt:       embeddings.GeneratedAt,
	}

	// Set document type if available
	if doc.Metadata != nil && doc.Metadata.DocumentType.Name != "" {
		vectorDoc.DocType = doc.Metadata.DocumentType.Name
	}

	// Add AI summary metadata if available
	if summaryVal, ok := doc.GetCustom("ai_summary"); ok {
		if summary, ok := summaryVal.(*ai.DocumentSummary); ok {
			vectorDoc.Summary = summary.ExecutiveSummary
			vectorDoc.KeyPoints = summary.KeyPoints
			vectorDoc.Topics = summary.Topics
			vectorDoc.Tags = summary.Tags
		}
	}

	// Convert chunk embeddings
	if len(embeddings.Chunks) > 0 {
		vectorDoc.ChunkEmbeddings = make([]search.ChunkEmbedding, len(embeddings.Chunks))
		for i, chunk := range embeddings.Chunks {
			vectorDoc.ChunkEmbeddings[i] = search.ChunkEmbedding{
				ChunkIndex: chunk.ChunkIndex,
				Text:       chunk.Text,
				Embedding:  chunk.Embedding,
				StartPos:   chunk.StartPos,
				EndPos:     chunk.EndPos,
			}
		}
	}

	// Index in vector search
	if err := c.VectorDB.IndexEmbedding(ctx, vectorDoc); err != nil {
		return fmt.Errorf("failed to index vector embeddings: %w", err)
	}

	c.Logger.Info("vector embeddings indexed",
		"document_id", doc.Document.ID,
		"title", doc.Document.Name,
	)

	doc.SetCustom("vector_indexed", true)
	doc.SetCustom("vector_indexed_at", time.Now())

	return nil
}

// ExecuteBatch implements BatchCommand for batch vector indexing.
func (c *IndexVectorCommand) ExecuteBatch(ctx context.Context, docs []*indexer.DocumentContext) error {
	// Collect documents with embeddings
	vectorDocs := make([]*search.VectorDocument, 0, len(docs))

	for _, doc := range docs {
		embeddingsVal, ok := doc.GetCustom("ai_embeddings")
		if !ok {
			continue
		}

		embeddings, ok := embeddingsVal.(*ai.DocumentEmbeddings)
		if !ok || len(embeddings.ContentEmbedding) == 0 {
			continue
		}

		// Build vector document
		vectorDoc := &search.VectorDocument{
			ObjectID:         doc.Document.ID,
			DocID:            doc.Document.ID,
			Title:            doc.Document.Name,
			ModifiedAt:       doc.Document.ModifiedTime,
			ContentEmbedding: embeddings.ContentEmbedding,
			Model:            embeddings.Model,
			Dimensions:       embeddings.Dimensions,
			EmbeddedAt:       embeddings.GeneratedAt,
		}

		if doc.Metadata != nil && doc.Metadata.DocumentType.Name != "" {
			vectorDoc.DocType = doc.Metadata.DocumentType.Name
		}

		if summaryVal, ok := doc.GetCustom("ai_summary"); ok {
			if summary, ok := summaryVal.(*ai.DocumentSummary); ok {
				vectorDoc.Summary = summary.ExecutiveSummary
				vectorDoc.KeyPoints = summary.KeyPoints
				vectorDoc.Topics = summary.Topics
				vectorDoc.Tags = summary.Tags
			}
		}

		if len(embeddings.Chunks) > 0 {
			vectorDoc.ChunkEmbeddings = make([]search.ChunkEmbedding, len(embeddings.Chunks))
			for i, chunk := range embeddings.Chunks {
				vectorDoc.ChunkEmbeddings[i] = search.ChunkEmbedding{
					ChunkIndex: chunk.ChunkIndex,
					Text:       chunk.Text,
					Embedding:  chunk.Embedding,
					StartPos:   chunk.StartPos,
					EndPos:     chunk.EndPos,
				}
			}
		}

		vectorDocs = append(vectorDocs, vectorDoc)
	}

	if len(vectorDocs) == 0 {
		c.Logger.Debug("no documents with embeddings to index")
		return nil
	}

	c.Logger.Info("batch indexing vector embeddings",
		"count", len(vectorDocs),
	)

	// Batch index
	if err := c.VectorDB.IndexEmbeddingBatch(ctx, vectorDocs); err != nil {
		return fmt.Errorf("failed to batch index vector embeddings: %w", err)
	}

	c.Logger.Info("vector embeddings batch indexed",
		"count", len(vectorDocs),
	)

	// Mark all as indexed
	indexedAt := time.Now()
	for _, doc := range docs {
		if _, ok := doc.GetCustom("ai_embeddings"); ok {
			doc.SetCustom("vector_indexed", true)
			doc.SetCustom("vector_indexed_at", indexedAt)
		}
	}

	return nil
}
